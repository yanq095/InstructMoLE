{
    "lora_config": {
      "r": 256,
      "lora_alpha": 256,
      "init_lora_weights": "gaussian",
      "target_modules": [
        "x_embedder",
        "attn.to_q",
        "attn.to_k",
        "attn.to_v",
        "attn.to_out.0",
        "norm1.linear",
        "norm.linear",
        "ff.net.0.proj",
        "single_transformer_blocks.*.proj_mlp" 
      ]
    },
    "moe_config": {
      "mole_expert": "LoRAMoE",
      "num_experts": 8,
      "num_experts_per_tok": 4,
      "rank": 32,
      "alpha": 32,
      "dropout": 0.0,
      "train_mole_only": true,
      "type_aux_loss_alpha": 0.1,
      "token_aux_loss_alpha": 0.01,
      "orthogonal_reg_alpha": 0.01,
      "use_type_embedding": true,
      "routing_policy": "default",
      "target_modules": [
        "ff.net.2",
        "single_transformer_blocks.*.proj_out"
      ],
      "token_route_overrides_double": [],
      "token_route_overrides_single": []
    }
  }
  